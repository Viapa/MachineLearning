### SMO原理介绍 ###

# <基本思想>:
# SMO把原始求解N个参数(λi)的二次规划问题分解成很多个子二次规划问题分别求解
# 每个子问题只需要求解2个λ参数，方法类似于坐标上升，节省时间成本和降低了内存需求。
# 每次启发式选择两个变量进行优化，不断循环，直到达到函数最优值。

# <原理分析>:

# 1. 视为一个二元函数:
# 采用坐标上升法，在求解λ1时可以固定其他N-1个参数，将函数看成只关于λ1的一元函数进行求解
# 但注意到SVM的等式约束条件: Σλi * yi = 0, 所以当固定其他参数时，参数λ1也被固定，因此此种方法不可用
# 因此，SMO选择每次优化两个λ参数, 固定其他N-2个参数: 如选择λ1和λ2, 固定λ3,λ4,...,λn
# 这样可以将目标函数视作只关于λ1和λ2的二元函数，其余不包含λ1和λ2的部分用常数(Constant)表示:
# min(λ) L(λ) = ΣΣλi*λj*yi*yj*(xiT*xj) / 2 - Σλi
# = min L(λ1,λ2) = 1/2 * K11 * y1^2 * λ1^2 + 1/2 * K22 * y2^2 * λ2^2 + 2 * 1/2 * K12 * y1*y2 * λ1*λ2 - (λ1 + λ2) + λ1*y1*v1 + λ2*y2*v2 + Constant
# = min L(λ1,λ2) = 1/2 * K11 * λ1^2 + 1/2 * K22 * λ2^2 + K12 * y1*y2 * λ1*λ2 - (λ1 + λ2) + λ1*y1*v1 + λ2*y2*v2 + Constant
# 其中, Kij = (xiT*xj) v1,v2表示累乘的常量(当i=1或2时,j≠1,2)  ...(1)

# 2. 转变为一元函数:
# 由约束Σλi * yi = 0: λ1*y1 + λ2*y2 = -Σ(i≠1,2) yi * λi = η (常数)
# 所以 λ1*y1 + λ2*y2 = η, 等式左右同时乘以y1: λ1*y1^2 + λ2*y2*y1 = η*y1 --> λ1 = η*y1 - λ2*y2*y1 = y1*(η-λ2*y2)  ...(2)
# 将(2)式带入(1)中得到只关于λ2的一元函数，由于常数项不影响目标函数的解，以下省略掉常数项Constant部分:
# min L(λ2) = 1/2 * K11 * λ1^2 + 1/2 * K22 * λ2^2 + K12 * y1*y2 * λ1*λ2 - (λ1 + λ2) + λ1*y1*v1 + λ2*y2*v2
# = 1/2*K11*(η-λ2*y2)^2 + 1/2*K22*λ2^2 + K12*y1*y2*y1*(η-λ2*y2)*λ2 - (y1*(η-λ2*y2) + λ2) + y1*(η-λ2*y2)*y1*v1 + λ2*y2*v2
# = 1/2*K11*(η-λ2*y2)^2 + 1/2*K22*λ2^2 + K12*y2*(η-λ2*y2)*λ2 - y1*(η-λ2*y2) - λ2 + (η-λ2*y2)*v1 + λ2*y2*v2  ...(3)

# 3. 对一元函数求极值点:
# 对λ2求导并令为零:  ∂L / ∂λ2 = K11*(η-λ2*y2)*(-y2) + K22*λ2 + K12*y2*(η-2*λ2*y2) + y1*y2 - 1 - v1*y2 + v2*y2 = 0
# 等价于 ∂L / ∂λ2 = -K11*η*y2 + K11*λ2 + K22*λ2 + K12*y2*η - 2*K12*λ2 + y1*y2 - 1 - v1*y2 + v2*y2 = 0
# 等价于 ∂L / ∂λ2 = (K11 + K22 - 2*K12)*λ2 - K11*y2*η + K12*y2*η + y1*y2 - 1 - v1*y2 + v2*y2 = 0  ...(4)

# 由上式必可求得λ2的解，将其带入(2)式中可得出λ1的解，分别记作λ1(new)和λ2(new)，而优化前的初始解记作λ1(old)和λ2(old),由Σλi * yi = 0约束可得:
# λ1(old)*y1 + λ2(old)*y2 = -Σ(i≠1,2) yi * λi = η --> η =λ1(old)*y1 + λ2(old)*y2  ...(5)

# 假设SVM超平面方程 f(w) = wTx + b, 且已推得: f(xi) = Σλi*yi*Kij + b, f(xi)表示样本xi的预测值, yi表示真实值  ...(6)
# 则可以定义误差: Ei = f(xi) - yi  ...(7)

# 由于上述vi表示除了i=1,2以外的累乘常数, 即 vi = Σ(j≠1,2)λj*yj*Kij, i=1,2.
# 故由(6)式得: v1 = f(x1) - Σ(j=1,2)λj*yj*K1j - b  ...(8) ; v2 = f(x2) - Σ(j=1,2)λj*yj*K2j - b  ...(9)

# 将(5),(8),(9)代入(4)中得: (K11 + K22 - 2*K12)*λ2 - K11*y2*η + K12*y2*η + y1*y2 - 1 - v1*y2 + v2*y2 = 0
# 等价于 (K11 + K22 - 2*K12)*λ2 = K11*y2*η - K12*y2*η - y1*y2 + 1 + v1*y2 - v2*y2
# 等价于 (K11 + K22 - 2*K12)*λ2(new) = (K11 - K12)*y2*(λ1(old)*y1 + λ2(old)*y2) - y1*y2 + 1 + y2*(f(x1) - Σ(j=1,2)λj*yj*K1j - b - (f(x2) - Σ(j=1,2)λj*yj*K2j - b))
# 等价于 (K11 + K22 - 2*K12)*λ2(new) = (K11 + K22 - 2K12)λ2(old) + y2*(y2 - y1 + f(x1) - f(x2))  ...(10) 注: 使用λ1 = y1*(η-λ2*y2)
# 带入(6)式并记 ξ = K11 + K22 - 2*K12 (常量) , 得: λ2(new) = λ2(old) + y2*(E1 - E2) / ξ  ...(11)

# 4. 对原始解进行裁剪:
# 这里的 λ2(new) 还没有考虑约束条件 0 <= λ1,λ2 <= C, λ1*y1 + λ2*y2 = η （C为预设的惩罚因子)
# 相当于动态规划中的 x1*y1 + x2*y2 = η, s.t. x1,x2 ∈[0,C]
# 则对y1, y2有两种情况需要讨论:
# 1. 当 y1 = y2 : 斜率k为负数, 二维框的长 L = max(0, λ2(old) + λ1(old) - C), 高 H = min(C, λ2(old) + λ1(old))  ...(12)
# 2. 当 y1 ≠ y2 : 斜率k为正数, 二维框的长 L = max(0, λ2(old) - λ1(old)), 高 H = min(C, C + λ2(old) - λ1(old))  ...(13)

# 由此可知，对λ1,λ2进行裁剪有以下规则:
# 当 λ2(new,un-clipped) > H : λ2(new) = H
# 当 L <= λ2(new,un-clipped) <= H : λ2(new) = λ2(new,un-clipped)
# 当 λ2(new,un-clipped) < L : λ2(new) = L

# 5. 求解λ1(new):
# 由 λ1*y1 + λ2*y2 = η --> λ1(old)*y1 + λ2(old)*y2 = λ1(new)*y1 + λ2(new)*y2 两边同乘以y1
# 所以 λ1(new) = λ1(old) + y1*y2*(λ2(old) - λ2(new))  ...(14)

# 6. 计算b:
# (1) if 0 < λ1(new) < C: b1(new) = -E1 - y1*K11*(λ1(new) - λ1(old)) - y2*K21*(λ2(new) - λ2(old)) + b(old)
# (2) if 0 < λ2(new) < C: b2(new) = -E2 - y1*K12*(λ1(new) - λ1(old)) - y2*K22*(λ2(new) - λ2(old)) + b(old)
# (3) 如果 λ1(new)， λ2(new) 同时满足上述条件时，则 b1(new) = b2(new)
# (4) 如果 λ1(new)， λ2(new) 是0或C，则 b1(new), b2(new) 以及它们之间的数都符合KKT条件，此时选取中点作为b(new)

# 7. 计算Ei:
# Ei(new) = Σλi*yi*K(xi,xj) + b(new) - yi

# <启发式选取变量>:
# 上述分析是在从N个变量中已经选出两个变量进行优化的方法
# 那么, 如何高效地选择两个变量进行优化，使得目标函数下降的最快？

# 1. 第一个变量选择
# 第一个变量的选择称为外循环，首先遍历整个样本集，选择违反KKT条件的αi作为第一个变量，接着依据相关规则选择第二个变量(见下面分析)
# 对这两个变量采用上述方法进行优化。
# 当遍历完整个样本集后，遍历非边界样本集（0<αi<C）中违反KKT的αi作为第一个变量，同样依据相关规则选择第二个变量，对此两个变量进行优化 。
# 当遍历完非边界样本集后，再次回到遍历整个样本集中寻找，即在整个样本集与非边界样本集上来回切换，寻找违反KKT条件的αi作为第一个变量 。
# 直到遍历整个样本集后，没有违反KKT条件αi，然后退出。
# 这是因为边界上的样本对应的 αi=0 或者 αi=C，在优化过程中很难变化，然而非边界样本0<αi<C会随着对其他变量的优化会有大的变化。 


# 2. 第二个变量选择
# 第二个变量的选择过程为内循环，假设在外循环中找个第一个变量记为α1，第二个变量的选择希望能使α2有较大的变换
# 由于α2是依赖于|E1-E2|，当E1为正时，那么选择最小的Ei作为E2
# 如果E1为负，选择最大Ei作为E2
# 通常为每个样本的Ei保存在一个列表中，选择最大的|E1-E2|来近似最大化步长。

